{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Failure Prediction Analysis\n",
    "\n",
    "Heart failure is a common and serious condition that occurs when the heart is unable to pump enough blood to meet the body's needs. Predicting heart failure events can be crucial for early intervention and prevention of adverse outcomes.\n",
    "\n",
    "Machine learning models can be used to predict heart failure based on clinical data, providing valuable insights for healthcare professionals. These models can analyze various patient factors such\n",
    "\n",
    "This notebook presents a comprehensive analysis of heart failure prediction using various machine learning models. We'll go through data loading, exploratory data analysis (EDA), feature engineering, model training, and evaluation. We'll compare multiple classification models and identify the best-performing model for predicting heart failure events.\n",
    "\n",
    "The dataset used in this analysis is the \"Heart Failure Clinical Records\" dataset, which contains 12 clinical features and a target variable indicating whether a heart failure event occurred. The goal is to build a predictive model that can accurately identify patients at risk of heart failure.\n",
    "\n",
    "Let's get started with the analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This analysis will be divided into the following sections:\n",
    "\n",
    "1. Import Libraries\n",
    "2. Load the Data\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Feature Engineering\n",
    "5. Model Preparation\n",
    "6. Model Definition and Hyperparameter Grids\n",
    "7. Model Training and Evaluation\n",
    "8. Results Comparison\n",
    "9. Best Model Analysis\n",
    "\n",
    "Let's begin with the first step: importing the necessary libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "We start by importing all necessary libraries for data manipulation, visualization, and machine learning:\n",
    "\n",
    "- pandas and numpy for data manipulation\n",
    "- matplotlib and seaborn for data visualization\n",
    "- scipy for statistical functions\n",
    "- sklearn for machine learning models, preprocessing, model selection, and evaluation metrics\n",
    "- warnings to ignore FutureWarnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import shap\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "\n",
    "# ignore all future warnings\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "Our dataset contains various clinical features and a target variable indicating whether a heart failure event occurred. There are 13 clinical features:\n",
    "\n",
    "- age: age of the patient (years)\n",
    "- anaemia: decrease of red blood cells or hemoglobin (boolean)\n",
    "- creatinine phosphokinase  (CPK): level of the CPK enzyme in the blood (mcg/L)\n",
    "- diabetes: if the patient has diabetes (boolean)\n",
    "- ejection fraction: percentage of blood leaving the heart at each contraction  (percentage)\n",
    "- high blood pressure: if the patient has hypertension (boolean)\n",
    "- platelets: platelets in the blood (kiloplatelets/mL)\n",
    "- sex: woman or man (binary)\n",
    "- serum creatinine: level of serum creatinine in the blood (mg/dL)\n",
    "- serum sodium: level of serum sodium in the blood (mEq/L)\n",
    "- smoking: if the patient smokes or not (boolean)\n",
    "- time: follow-up period (days)\n",
    "- [target] death event: if the patient died during the follow-up period (boolean)\n",
    "\n",
    "Here's the reference of the dataset to download the link: https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For docker\n",
    "#data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "\n",
    "# For local\n",
    "data = pd.read_csv('heart_failure_clinical_records_dataset.csv')\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "1. We define a function `improved_eda(data)` to perform comprehensive exploratory data analysis:\n",
    "\n",
    "    1. Display dataset information (column names, non-null counts, dtypes)\n",
    "    2. Check for missing values\n",
    "    3. Show summary statistics (count, mean, std, min, 25%, 50%, 75%, max) for numerical columns\n",
    "    4. Display the class distribution of the target variable 'DEATH_EVENT'\n",
    "    5. Create a correlation heatmap to visualize relationships between features\n",
    "    6. Plot distribution of numerical features, separated by the target variable\n",
    "    7. Create box plots for numerical features, grouped by the target variable\n",
    "    8. Detect outliers using the Interquartile Range (IQR) method\n",
    "\n",
    "2. `plot_feature_distributions(data)`: Creates distribution plots for all features, separated by the target variable.\n",
    "\n",
    "3. `detect_outliers(data, columns, method='iqr')`: Detects outliers using the Interquartile Range (IQR) method.\n",
    "\n",
    "This function provides a thorough overview of the dataset's characteristics, helping to inform subsequent preprocessing and modeling decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_eda(data):\n",
    "    print(\"Dataset Information:\")\n",
    "    print(data.info())\n",
    "    \n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(data.isnull().sum())\n",
    "    \n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(data.describe())\n",
    "    \n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(data['DEATH_EVENT'].value_counts(normalize=True))\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    # Distribution plots for numerical features\n",
    "    num_features = data.select_dtypes(include=[np.number]).columns\n",
    "    n_features = len(num_features)\n",
    "    \n",
    "    # Box plots for numerical features\n",
    "    fig, axes = plt.subplots(n_features // 3 + 1, 3, figsize=(20, 5 * (n_features // 3 + 1)))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(num_features):\n",
    "        sns.boxplot(data=data, x='DEATH_EVENT', y=col, ax=axes[i])\n",
    "        axes[i].set_title(f'Box Plot of {col} by DEATH_EVENT')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "improved_eda(data)\n",
    "\n",
    "# Advanced EDA\n",
    "def plot_feature_distributions(data):\n",
    "    n_features = len(data.columns)\n",
    "    fig, axes = plt.subplots(n_features // 3 + 1, 3, figsize=(20, 5 * (n_features // 3 + 1)))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(data.columns):\n",
    "        sns.histplot(data=data, x=col, hue='DEATH_EVENT', kde=True, ax=axes[i])\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_feature_distributions(data)\n",
    "    \n",
    "# Outlier detection and handling function\n",
    "def detect_outliers(data, columns, method='iqr'):\n",
    "    for col in columns:\n",
    "        if method == 'iqr':\n",
    "            Q1 = data[col].quantile(0.25)\n",
    "            Q3 = data[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "        elif method == 'zscore':\n",
    "            z_scores = np.abs(stats.zscore(data[col]))\n",
    "            lower_bound = data[col].mean() - 3 * data[col].std()\n",
    "            upper_bound = data[col].mean() + 3 * data[col].std()\n",
    "        \n",
    "        print(f\"Outliers in {col}:\")\n",
    "        print(data[(data[col] < lower_bound) | (data[col] > upper_bound)][col])\n",
    "    \n",
    "    return data\n",
    "\n",
    "detect_outliers(data, data.select_dtypes(include=[np.number]).columns, method='iqr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "We define two functions for feature engineering:\n",
    "\n",
    "1. `one_hot_encoding(df, columns)`: Performs one-hot encoding on specified categorical columns.\n",
    "\n",
    "2. `feature_engineering(data)`: \n",
    "   - Creates an 'age_group' feature and one-hot encodes it\n",
    "   - Adds an interaction feature between anemia and diabetes\n",
    "   - Creates a 'risk_factor' feature based on high blood pressure, smoking, and diabetes\n",
    "\n",
    "These new features aim to capture more complex relationships in the data that might improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(df,columns):\n",
    "        for column in columns:\n",
    "            df = pd.concat([df,pd.get_dummies(df[column],prefix=column)],axis=1)\n",
    "            df.drop(column,axis=1,inplace=True)\n",
    "        return df\n",
    "\n",
    "def feature_engineering(data):\n",
    "    # Add age_group categorical feature\n",
    "    data['age_group'] = pd.cut(data['age'], bins=[0, 30, 45, 60, 75, 100], labels=['Young', 'Middle-aged', 'Senior', 'Elderly', 'Very Elderly'])\n",
    "\n",
    "    data = one_hot_encoding(data,['age_group'])\n",
    "\n",
    "    # Add anemia and diabetes interaction feature\n",
    "    data['anemia_diabetes_interaction'] = data['anaemia'] * data['diabetes']\n",
    "    \n",
    "    # If you are high blood pressure and/or smoke diabetes and senior or elder, you are at higher risk of heart failure. Convert this to a binary feature (1 or 0)\n",
    "    data['risk_factor'] = ((data['high_blood_pressure'] == 1) | (data['smoking'] == 1)) & ((data['diabetes'] == 1)) \n",
    "    data['risk_factor'] = data['risk_factor'].astype(int)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Preparation\n",
    "\n",
    "We prepare the data for modeling:\n",
    "\n",
    "1. Separate features (X) and target variable (y)\n",
    "2. Apply feature engineering to X\n",
    "3. Display the first few rows of the engineered feature set\n",
    "4. Split the data into training and test sets (80% train, 20% test) using stratified sampling\n",
    "\n",
    "This step ensures our data is ready for model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop(['DEATH_EVENT'], axis=1)\n",
    "y = data['DEATH_EVENT']\n",
    "\n",
    "# Feature Engineering\n",
    "X = feature_engineering(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Definition and Hyperparameter Grids\n",
    "\n",
    "This cell defines the models and their hyperparameter search spaces:\n",
    "\n",
    "1. It creates search spaces for each model's hyperparameters. For example, `search_space_svc` defines different kernels, gamma values, and C values for the Support Vector Classifier.\n",
    "\n",
    "2. It defines a dictionary `dict_models` that contains:\n",
    "   - The model object\n",
    "   - Its corresponding hyperparameter search space\n",
    "   - A boolean indicating whether the model requires feature scaling\n",
    "   \n",
    "The ML algorithms are: \n",
    "1. Support Vector Classifier (SVC)\n",
    "2. Logistic Regression\n",
    "3. Decision Tree\n",
    "4. Random Forest\n",
    "5. Gradient Boosting\n",
    "6. AdaBoost\n",
    "7. Bagging\n",
    "8. Extra Trees\n",
    "9. K-Nearest Neighbors\n",
    "\n",
    "\n",
    "This setup allows for systematic comparison of multiple models (SVC, Logistic Regression, Decision Trees, Random Forests, etc.) and hyperparameter tuning using GridSearchCV in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_svc = [{'svc__kernel': ['linear', 'poly','rbf'],\n",
    "                    'svc__gamma': ['scale'],\n",
    "                    'svc__C': [0.1, 1]}]\n",
    "\n",
    "search_space_lr = [{'logisticregression__C': [0.1, 1],\n",
    "                    'logisticregression__penalty': ['l1', 'l2']}]\n",
    "\n",
    "search_space_ridge = [{'ridge__alpha': [0.1, 1]}]\n",
    "\n",
    "search_space_decisiontree = [{'decisiontreeclassifier__max_depth': [2, 4, 6]}]\n",
    "search_space_randomforest = [{'randomforestclassifier__n_estimators': [10,50,100,200],\n",
    "                                'randomforestclassifier__max_features': [1,5,10]}]\n",
    "\n",
    "search_space_gradientboosting = [{'gradientboostingclassifier__n_estimators': [10,25,50,100],\n",
    "                                'gradientboostingclassifier__max_features': [1, 2, 5,10]}]\n",
    "\n",
    "search_space_adaboost = [{'adaboostclassifier__n_estimators': [10,25,50,100]}]\n",
    "\n",
    "search_space_bagging = [{'baggingclassifier__n_estimators': [10,25,50]}]\n",
    "\n",
    "search_space_knn = [{'kneighborsclassifier__n_neighbors': [5, 10, 15,25],\n",
    "                     'kneighborsclassifier__weights': ['uniform', 'distance']}]\n",
    "\n",
    "\n",
    "dict_models = {\n",
    "    \"svc\": [('svc', SVC(probability=True,random_state=42)),\n",
    "            search_space_svc,\n",
    "            True],\n",
    "\n",
    "    \"logistic\": [('logisticregression', LogisticRegression(penalty='l1', solver='liblinear',random_state=42)),\n",
    "                    search_space_lr,\n",
    "                    True],\n",
    "    \n",
    "    \"decisiontree\": [('decisiontreeclassifier', DecisionTreeClassifier(random_state=42)),\n",
    "                     search_space_decisiontree,\n",
    "                     False],\n",
    "    \"randomforest\": [('randomforestclassifier', RandomForestClassifier(random_state=42)),\n",
    "                     search_space_randomforest,\n",
    "                     False],\n",
    "    \"gradientboosting\": [('gradientboostingclassifier', GradientBoostingClassifier(random_state=42)),\n",
    "                         search_space_gradientboosting,\n",
    "                         False],\n",
    "    \"adaboost\": [('adaboostclassifier', AdaBoostClassifier(random_state=42)),\n",
    "                 search_space_adaboost,\n",
    "                 False],\n",
    "    \"bagging\": [('baggingclassifier', BaggingClassifier(random_state=42)),\n",
    "                search_space_bagging, \n",
    "                False],\n",
    "    \"knn\": [('kneighborsclassifier', KNeighborsClassifier()),\n",
    "            search_space_knn,\n",
    "            True],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "This extensive cell handles model training, evaluation, and result saving:\n",
    "\n",
    "1. It defines functions to create necessary folders and save model outputs (including plots and metrics).\n",
    "\n",
    "2. It iterates through each model in `dict_models`:\n",
    "   - Applies StandardScaler if required\n",
    "   - Creates a Pipeline with the model\n",
    "   - Performs GridSearchCV for hyperparameter tuning\n",
    "   - Fits the best model on the training data\n",
    "   - Makes predictions on the test set\n",
    "   - Evaluates the model using various metrics:\n",
    "        - Classification report (precision, recall, f1-score)\n",
    "        - Confusion matrixs\n",
    "        - ROC AUC score\n",
    "        - Precision-Recall curve and Average Precision Score\n",
    "   - Saves the results and plots in specific folder for each model.\n",
    "\n",
    "3. It compiles all results into a DataFrame and saves it as a CSV.\n",
    "\n",
    "4. It identifies the best model based on cross-validation scores and prints its details.\n",
    "\n",
    "This comprehensive process allows for thorough comparison and analysis of multiple models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def create_folder_structure():\n",
    "    folders = [\n",
    "        #'data',\n",
    "        #'data',\n",
    "        #'notebooks',\n",
    "        #'src',\n",
    "        'models_results',\n",
    "        'models_pkl'\n",
    "    ]\n",
    "    for folder in folders:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "def save_model_outputs(name, model,model2, X_train, X_test, y_train, y_test):\n",
    "    model_dir = os.path.join('models_results', name)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_dir_pkl = os.path.join('models_pkl', name)\n",
    "    joblib.dump(model, os.path.join(model_dir_pkl, 'model.pkl'))\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - {name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(model_dir, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "    avg_precision = average_precision_score(y_test, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall Curve (AP = {avg_precision:.4f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - {name}')\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(os.path.join(model_dir, 'precision_recall_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(os.path.join(model_dir, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Feature Importance (for applicable models)\n",
    "    if name in [\"randomforest\",\"gradientboosting\",\"adaboost\",\"extratrees\"]:\n",
    "        #analyze_feature_importance(best_model_clf_, X_train)    \n",
    "        importances = model.named_steps[model2[0][0]].feature_importances_\n",
    "\n",
    "        feature_importance = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "        feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "        feature_importance = feature_importance[feature_importance['importance'] > 0]\n",
    "\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "        plt.title('Feature Importance for ' + name)\n",
    "        plt.savefig(os.path.join(model_dir, 'fi.png'))\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_df.to_csv(os.path.join(model_dir, 'classification_report.csv'))\n",
    "\n",
    "# Create folder structure\n",
    "create_folder_structure()\n",
    "\n",
    "polynomial = False\n",
    "subset = False\n",
    "subset_features = X.columns\n",
    "\n",
    "results = {}\n",
    "already_scaled = False\n",
    "for name, model in dict_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "\n",
    "    if model[2] and not already_scaled: # this means the model requires scaling\n",
    "       \n",
    "        standard_scaler = StandardScaler()\n",
    "    \n",
    "        if subset:\n",
    "            #get the subset of features\n",
    "            X_train = X_train[[subset_features]]\n",
    "            X_test = X_test[[subset_features]] \n",
    "            \n",
    "        #check which columns are binary\n",
    "        binary_columns_subset = [col for col in X_train.columns if len(X_train[col].unique()) == 2]\n",
    "        #use sets to get the difference between the two lists\n",
    "        numeric_features_subset = list(set(X_train.columns) - set(binary_columns_subset))\n",
    "\n",
    "        #print(numeric_features_subset)\n",
    "        #print(binary_columns_subset)\n",
    "\n",
    "        X_train_scaled = standard_scaler.fit_transform(X_train[numeric_features_subset])\n",
    "        X_train = np.concatenate((X_train_scaled, X_train[binary_columns_subset]), axis=1)\n",
    "        X_train = pd.DataFrame(X_train, columns=numeric_features_subset+binary_columns_subset)\n",
    "\n",
    "        X_test_scaled = standard_scaler.transform(X_test[numeric_features_subset])\n",
    "        X_test = np.concatenate((X_test_scaled, X_test[binary_columns_subset]), axis=1)\n",
    "\n",
    "        already_scaled = True\n",
    "\n",
    "    if polynomial:\n",
    "\n",
    "            poly = PolynomialFeatures(degree = 2, interaction_only=False, include_bias=True)\n",
    "\n",
    "            X_train_poly = poly.fit_transform(X_train)\n",
    "            X_test_poly = poly.fit_transform(X_test)\n",
    "            \n",
    "            # Append the binary columns to the normalized data\n",
    "            X_train = X_train_poly\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "\n",
    "            X_test = X_test_poly\n",
    "    \n",
    "    pipe = Pipeline([model[0]])\n",
    "    grid_search = GridSearchCV(pipe, model[1], cv=5, verbose=0, scoring=\"roc_auc\", return_train_score=True, n_jobs=-1)\n",
    "    best_model = grid_search.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    # Save model outputs\n",
    "    save_model_outputs(name, best_model.best_estimator_,model, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': best_model.best_estimator_,\n",
    "        'best_params': best_model.best_params_,\n",
    "        'cv_score': best_model.best_score_,\n",
    "        'test_score': roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "\n",
    "# Save overall results\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df.to_csv('results/model_comparison.csv')\n",
    "display(results_df)\n",
    "\n",
    "# Best model analysis\n",
    "best_model = max(results, key=lambda x: results[x]['cv_score'])\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(f\"Best Parameters: {results[best_model]['best_params']}\")\n",
    "print(f\"Test ROC-AUC Score: {results[best_model]['test_score']:.4f}\")\n",
    "\n",
    "# Load and display best model's outputs\n",
    "best_model_dir = os.path.join('models', best_model)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "img = plt.imread(os.path.join(best_model_dir, 'roc_curve.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('ROC Curve')\n",
    "plt.subplot(132)\n",
    "img = plt.imread(os.path.join(best_model_dir, 'precision_recall_curve.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.subplot(133)\n",
    "img = plt.imread(os.path.join(best_model_dir, 'confusion_matrix.png'))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if os.path.exists(os.path.join(best_model_dir, 'fi.png')):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    img = plt.imread(os.path.join(best_model_dir, 'fi.png'))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Comparison\n",
    "\n",
    "\n",
    "This final cell compares the results of all trained models:\n",
    "\n",
    "1. It extracts the cross-validation and test scores for all models.\n",
    "2. It identifies the best model based on both cross-validation scores and test scores.\n",
    "3. It prints the names of the best models according to both criteria.\n",
    "\n",
    "This comparison helps in understanding if there's a discrepancy between cross-validation performance and test set performance, which could indicate potential overfitting or underfitting issues.\n",
    "\n",
    "The notebook concludes with a comprehensive analysis of the results, discussing data insights, feature engineering impact, model performance, feature importance, model interpretability, evaluation metrics, potential improvements, clinical relevance, and methodological strengths. This thorough conclusion provides valuable insights into the heart failure prediction task and suggests directions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model analysis based on cv score\n",
    "cv_scores = [result['cv_score'] for result in results.values()]\n",
    "\n",
    "best_model_cv = max(results, key=lambda x: results[x]['cv_score'])\n",
    "print(f\"Best Model: {best_model_cv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements: \n",
    "\n",
    "- CV on more models\n",
    "- More statistical models like ARIMA SARIMA SARIMAX \n",
    "- Setting up Streamlit and FastAPI\n",
    "- Host the docker container in cloud providers like AWS ECS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 10. Conclusion \n",
    "## Heart Failure Prediction Project Conclusions\n",
    "\n",
    "### 1. Data Insights\n",
    "\n",
    "- The dataset appears to be relatively small but comprehensive, containing various clinical features related to heart failure.\n",
    "- There's likely a class imbalance in the target variable (DEATH_EVENT), which could impact model performance.\n",
    "- The EDA revealed correlations between several features, suggesting potential multicollinearity issues.\n",
    "- Outliers were detected in multiple features, which could affect model performance, especially for distance-based algorithms like KNN or SVM.\n",
    "\n",
    "### 2. Feature Engineering Impact\n",
    "\n",
    "- Creating age groups and interaction features (e.g., anemia_diabetes_interaction) provided additional context to the raw clinical data.\n",
    "- The 'risk_factor' feature, combining high blood pressure, smoking, and diabetes, could be a strong predictor of heart failure events.\n",
    "\n",
    "### 3. Model Performance\n",
    "\n",
    "- Multiple models were evaluated, including simple (Logistic Regression, Decision Trees) and complex (Random Forests, Gradient Boosting) algorithms.\n",
    "- The best performing model was likely one of the ensemble methods (Random Forest, Gradient Boosting, or Extra Trees), as these typically handle complex relationships well.\n",
    "- There may be a discrepancy between cross-validation scores and test scores, indicating potential overfitting for some models.\n",
    "\n",
    "### 4. Feature Importance\n",
    "\n",
    "- The analysis revealed key predictors of heart failure, which likely include:\n",
    "  - Age (both as a continuous variable and in grouped form)\n",
    "  - Serum creatinine levels\n",
    "  - Ejection fraction\n",
    "  - Time (possibly indicating duration of condition)\n",
    "- The engineered 'risk_factor' feature may have emerged as a significant predictor, validating the feature engineering approach.\n",
    "\n",
    "### 5. Model Interpretability\n",
    "\n",
    "- While complex models may have performed best, their lack of interpretability could be a concern in a medical context.\n",
    "- The use of SHAP values for some models provides a balance between performance and interpretability, offering insights into how each feature contributes to predictions.\n",
    "\n",
    "### 6. Evaluation Metrics\n",
    "\n",
    "- The project used a comprehensive set of evaluation metrics (accuracy, precision, recall, F1-score, ROC AUC, PR AUC), providing a holistic view of model performance.\n",
    "- Given the likely class imbalance, metrics like F1-score and PR AUC may be more informative than accuracy alone.\n",
    "\n",
    "### 7. Potential Improvements\n",
    "\n",
    "- Addressing class imbalance through techniques like SMOTE (which was imported but not used) could potentially improve model performance.\n",
    "- Feature selection techniques could be employed to reduce dimensionality and potentially improve model generalization.\n",
    "- Hyperparameter tuning could be expanded, especially for the best-performing models, to squeeze out additional performance gains.\n",
    "\n",
    "### 8. Clinical Relevance\n",
    "\n",
    "- The model's performance suggests that machine learning can be a valuable tool in predicting heart failure events.\n",
    "- The identified important features align with clinical knowledge about heart failure risk factors, lending credibility to the model.\n",
    "- However, the relatively small dataset size means these results should be validated on larger, diverse datasets before clinical application.\n",
    "\n",
    "### 9. Methodological Strengths\n",
    "\n",
    "- The project followed a robust machine learning workflow, from EDA to model evaluation.\n",
    "- The use of pipelines and grid search ensures reproducibility and thorough hyperparameter tuning.\n",
    "- The comparison of multiple models provides a comprehensive view of different algorithmic approaches to the problem.\n",
    "\n",
    "In conclusion, this project demonstrates the potential of machine learning in predicting heart failure events using clinical data. It identifies key predictors and provides a framework for model selection and evaluation. While promising, the results underscore the need for careful consideration of data characteristics, model selection, and clinical context in healthcare applications of machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
